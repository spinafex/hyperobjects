import pandas as pd
import spacy
from sentence_transformers import SentenceTransformer
from scipy.spatial.distance import pdist
from scipy.cluster.hierarchy import linkage, fcluster

# Load NLP model (SpaCy for dependency parsing)
nlp = spacy.load("en_core_web_sm")

# Load term list
df = pd.read_csv("terms.csv", header=None)
terms = df[0].tolist()

# Example: Influence-based relationship terms
influence_types = ["contributes", "directs", "facilitates", "incentivizes", "influences", "regulates"]

# Step 1: Extract influence-based relationships using SpaCy
relations = []
for term in terms:
    doc = nlp(term)
    for token in doc:
        if token.dep_ in ["ROOT", "acl", "xcomp"] and token.lemma_ in influence_types:
            subject = [child.text for child in token.children if child.dep_ == "nsubj"]
            object_ = [child.text for child in token.children if child.dep_ == "dobj"]
            if subject and object_:
                relations.append((subject[0], token.lemma_, object_[0]))

# Step 2: Generate Term Embeddings
model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = model.encode(terms, convert_to_tensor=False)

# Step 3: Cluster Terms to Find Implicit Influence
cosine_distances = pdist(embeddings, metric="cosine")
linkage_matrix = linkage(cosine_distances, method="ward")
cluster_labels = fcluster(linkage_matrix, t=4, criterion="maxclust")

# Step 4: Assign Influence Relationships Based on Clusters
cluster_dict = {}
for term, cluster in zip(terms, cluster_labels):
    cluster_dict.setdefault(cluster, []).append(term)

for cluster_terms in cluster_dict.values():
    if len(cluster_terms) > 1:
        parent = cluster_terms[0]
        for term in cluster_terms[1:]:
            relations.append((term, "relates_to", parent))

# Step 5: Save to CSV for Neo4j
ontology_df = pd.DataFrame(relations, columns=["Source", "Relation", "Target"])
ontology_df.to_csv("influence_ontology.csv", index=False)

# Print a sample
print(ontology_df.head())
